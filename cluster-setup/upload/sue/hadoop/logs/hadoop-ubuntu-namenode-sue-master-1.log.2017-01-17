2017-01-17 19:13:44,197 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = sue-master-1/172.24.43.156
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.2.1
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.2 -r 1503152; compiled by 'mattf' on Mon Jul 22 15:23:09 PDT 2013
STARTUP_MSG:   java = 1.8.0_111
************************************************************/
2017-01-17 19:13:44,359 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-01-17 19:13:44,366 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2017-01-17 19:13:44,367 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-01-17 19:13:44,367 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-01-17 19:13:44,522 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2017-01-17 19:13:44,524 WARN org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Source name ugi already exists!
2017-01-17 19:13:44,536 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2017-01-17 19:13:44,537 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source NameNode registered.
2017-01-17 19:13:44,588 INFO org.apache.hadoop.hdfs.util.GSet: Computing capacity for map BlocksMap
2017-01-17 19:13:44,588 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2017-01-17 19:13:44,588 INFO org.apache.hadoop.hdfs.util.GSet: 2.0% max memory = 1005060096
2017-01-17 19:13:44,588 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2017-01-17 19:13:44,588 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2017-01-17 19:13:44,606 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=ubuntu
2017-01-17 19:13:44,606 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2017-01-17 19:13:44,606 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2017-01-17 19:13:44,613 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2017-01-17 19:13:44,613 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
2017-01-17 19:13:44,650 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStateMBean and NameNodeMXBean
2017-01-17 19:13:44,668 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: dfs.namenode.edits.toleration.length = 0
2017-01-17 19:13:44,668 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times 
2017-01-17 19:13:44,677 INFO org.apache.hadoop.hdfs.server.common.Storage: Start loading image file /app/hadoop/tmp/dfs/name/current/fsimage
2017-01-17 19:13:44,677 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2017-01-17 19:13:44,679 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2017-01-17 19:13:44,679 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file /app/hadoop/tmp/dfs/name/current/fsimage of size 112 bytes loaded in 0 seconds.
2017-01-17 19:13:44,679 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Start loading edits file /app/hadoop/tmp/dfs/name/current/edits
2017-01-17 19:13:44,679 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: EOF of /app/hadoop/tmp/dfs/name/current/edits, reached end of edit log Number of transactions found: 0.  Bytes read: 4
2017-01-17 19:13:44,679 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Start checking end of edit log (/app/hadoop/tmp/dfs/name/current/edits) ...
2017-01-17 19:13:44,679 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Checked the bytes after the end of edit log (/app/hadoop/tmp/dfs/name/current/edits):
2017-01-17 19:13:44,679 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Padding position  = -1 (-1 means padding not found)
2017-01-17 19:13:44,679 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Edit log length   = 4
2017-01-17 19:13:44,679 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Read length       = 4
2017-01-17 19:13:44,680 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Corruption length = 0
2017-01-17 19:13:44,680 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Toleration length = 0 (= dfs.namenode.edits.toleration.length)
2017-01-17 19:13:44,682 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Summary: |---------- Read=4 ----------|-- Corrupt=0 --|-- Pad=0 --|
2017-01-17 19:13:44,682 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edits file /app/hadoop/tmp/dfs/name/current/edits of size 4 edits # 0 loaded in 0 seconds.
2017-01-17 19:13:44,683 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file /app/hadoop/tmp/dfs/name/current/fsimage of size 112 bytes saved in 0 seconds.
2017-01-17 19:13:44,748 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: closing edit log: position=4, editlog=/app/hadoop/tmp/dfs/name/current/edits
2017-01-17 19:13:44,749 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: close success: truncate to 4, editlog=/app/hadoop/tmp/dfs/name/current/edits
2017-01-17 19:13:44,754 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-01-17 19:13:44,754 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 159 msecs
2017-01-17 19:13:44,755 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.safemode.threshold.pct          = 0.9990000128746033
2017-01-17 19:13:44,755 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-01-17 19:13:44,755 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.safemode.extension              = 30000
2017-01-17 19:13:44,755 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks excluded by safe block count: 0 total blocks: 0 and thus the safe blocks: 0
2017-01-17 19:13:44,765 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 0
2017-01-17 19:13:44,765 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2017-01-17 19:13:44,765 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 0
2017-01-17 19:13:44,765 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2017-01-17 19:13:44,765 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode termination scan for invalid, over- and under-replicated blocks completed in 10 msec
2017-01-17 19:13:44,765 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2017-01-17 19:13:44,765 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2017-01-17 19:13:44,765 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2017-01-17 19:13:44,776 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2017-01-17 19:13:44,779 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source FSNamesystemMetrics registered.
2017-01-17 19:13:44,787 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 0 msec
2017-01-17 19:13:44,787 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 0 msec processing time, 0 msec clock time, 1 cycles
2017-01-17 19:13:44,787 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 0 msec
2017-01-17 19:13:44,787 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 0 msec processing time, 0 msec clock time, 1 cycles
2017-01-17 19:13:44,788 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2017-01-17 19:13:44,789 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcDetailedActivityForPort54310 registered.
2017-01-17 19:13:44,789 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcActivityForPort54310 registered.
2017-01-17 19:13:44,790 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up at: sue-master-1/172.24.43.156:54310
2017-01-17 19:13:44,818 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-01-17 19:13:44,859 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2017-01-17 19:13:44,865 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2017-01-17 19:13:44,868 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50070
2017-01-17 19:13:44,868 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2017-01-17 19:13:44,868 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2017-01-17 19:13:44,869 INFO org.mortbay.log: jetty-6.1.26
2017-01-17 19:13:45,147 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2017-01-17 19:13:45,147 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2017-01-17 19:13:45,148 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-01-17 19:13:45,148 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 54310: starting
2017-01-17 19:13:45,149 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 54310: starting
2017-01-17 19:13:45,150 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 54310: starting
2017-01-17 19:13:45,150 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 54310: starting
2017-01-17 19:13:45,151 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 54310: starting
2017-01-17 19:13:45,151 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 54310: starting
2017-01-17 19:13:45,152 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 54310: starting
2017-01-17 19:13:45,152 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 54310: starting
2017-01-17 19:13:45,153 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 54310: starting
2017-01-17 19:13:45,153 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 54310: starting
2017-01-17 19:13:45,172 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 54310: starting
2017-01-17 19:13:46,115 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: node registration from 172.24.43.151:50010 storage DS-1258076912-172.24.43.151-50010-1484680426112
2017-01-17 19:13:46,118 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.24.43.151:50010
2017-01-17 19:13:46,121 INFO org.apache.hadoop.hdfs.StateChange: *BLOCK* NameNode.blocksBeingWrittenReport: from 172.24.43.151:50010 0 blocks
2017-01-17 19:13:46,140 INFO org.apache.hadoop.hdfs.StateChange: *BLOCK* processReport: from 172.24.43.151:50010, blocks: 0, processing time: 1 msecs
2017-01-17 19:13:46,142 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: node registration from 172.24.43.150:50010 storage DS-1653363127-172.24.43.150-50010-1484680426142
2017-01-17 19:13:46,142 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.24.43.150:50010
2017-01-17 19:13:46,145 INFO org.apache.hadoop.hdfs.StateChange: *BLOCK* NameNode.blocksBeingWrittenReport: from 172.24.43.150:50010 0 blocks
2017-01-17 19:13:46,152 INFO org.apache.hadoop.hdfs.StateChange: *BLOCK* processReport: from 172.24.43.150:50010, blocks: 0, processing time: 0 msecs
2017-01-17 19:13:46,173 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: node registration from 172.24.43.149:50010 storage DS-41009819-172.24.43.149-50010-1484680426172
2017-01-17 19:13:46,173 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.24.43.149:50010
2017-01-17 19:13:46,183 INFO org.apache.hadoop.hdfs.StateChange: *BLOCK* NameNode.blocksBeingWrittenReport: from 172.24.43.149:50010 0 blocks
2017-01-17 19:13:46,191 INFO org.apache.hadoop.hdfs.StateChange: *BLOCK* processReport: from 172.24.43.149:50010, blocks: 0, processing time: 1 msecs
2017-01-17 19:13:46,336 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: node registration from 172.24.43.148:50010 storage DS-73780359-172.24.43.148-50010-1484680426330
2017-01-17 19:13:46,336 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.24.43.148:50010
2017-01-17 19:13:46,339 INFO org.apache.hadoop.hdfs.StateChange: *BLOCK* NameNode.blocksBeingWrittenReport: from 172.24.43.148:50010 0 blocks
2017-01-17 19:13:46,347 INFO org.apache.hadoop.hdfs.StateChange: *BLOCK* processReport: from 172.24.43.148:50010, blocks: 0, processing time: 0 msecs
2017-01-17 19:13:51,535 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /hbase/hbase.version. blk_1308139046964299656_1001
2017-01-17 19:13:51,797 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addStoredBlock: blockMap updated: 172.24.43.148:50010 is added to blk_1308139046964299656_1001 size 7
2017-01-17 19:13:51,800 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addStoredBlock: blockMap updated: 172.24.43.149:50010 is added to blk_1308139046964299656_1001 size 7
2017-01-17 19:13:51,802 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addStoredBlock: blockMap updated: 172.24.43.151:50010 is added to blk_1308139046964299656_1001 size 7
2017-01-17 19:13:51,805 INFO org.apache.hadoop.hdfs.StateChange: Removing lease on  /hbase/hbase.version from client DFSClient_NONMAPREDUCE_-2025447869_1
2017-01-17 19:13:51,805 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/hbase.version is closed by DFSClient_NONMAPREDUCE_-2025447869_1
2017-01-17 19:13:51,818 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /hbase/hbase.id. blk_-1860355798423449393_1002
2017-01-17 19:13:51,897 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addStoredBlock: blockMap updated: 172.24.43.150:50010 is added to blk_-1860355798423449393_1002 size 42
2017-01-17 19:13:51,905 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addStoredBlock: blockMap updated: 172.24.43.151:50010 is added to blk_-1860355798423449393_1002 size 42
2017-01-17 19:13:51,907 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addStoredBlock: blockMap updated: 172.24.43.149:50010 is added to blk_-1860355798423449393_1002 size 42
2017-01-17 19:13:51,910 INFO org.apache.hadoop.hdfs.StateChange: Removing lease on  /hbase/hbase.id from client DFSClient_NONMAPREDUCE_-2025447869_1
2017-01-17 19:13:51,911 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/hbase.id is closed by DFSClient_NONMAPREDUCE_-2025447869_1
2017-01-17 19:13:52,038 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /hbase/data/hbase/meta/1588230740/.regioninfo. blk_3978675172161204725_1003
2017-01-17 19:13:52,139 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addStoredBlock: blockMap updated: 172.24.43.150:50010 is added to blk_3978675172161204725_1003 size 30
2017-01-17 19:13:52,142 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addStoredBlock: blockMap updated: 172.24.43.148:50010 is added to blk_3978675172161204725_1003 size 30
2017-01-17 19:13:52,146 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addStoredBlock: blockMap updated: 172.24.43.149:50010 is added to blk_3978675172161204725_1003 size 30
2017-01-17 19:13:52,149 INFO org.apache.hadoop.hdfs.StateChange: Removing lease on  /hbase/data/hbase/meta/1588230740/.regioninfo from client DFSClient_NONMAPREDUCE_-2025447869_1
2017-01-17 19:13:52,149 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/meta/1588230740/.regioninfo is closed by DFSClient_NONMAPREDUCE_-2025447869_1
2017-01-17 19:13:52,189 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /hbase/data/hbase/meta/1588230740/WALs/hlog.1484680432166. blk_-4251456357024774638_1004
2017-01-17 19:13:52,382 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /hbase/data/hbase/meta/1588230740/WALs/hlog.1484680432166 for DFSClient_NONMAPREDUCE_-2025447869_1
2017-01-17 19:13:52,771 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addStoredBlock: blockMap updated: 172.24.43.151:50010 is added to blk_-4251456357024774638_1004 size 17
2017-01-17 19:13:52,771 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addStoredBlock: blockMap updated: 172.24.43.149:50010 is added to blk_-4251456357024774638_1004 size 17
2017-01-17 19:13:52,774 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addStoredBlock: blockMap updated: 172.24.43.148:50010 is added to blk_-4251456357024774638_1004 size 17
2017-01-17 19:13:52,779 INFO org.apache.hadoop.hdfs.StateChange: Removing lease on  /hbase/data/hbase/meta/1588230740/WALs/hlog.1484680432166 from client DFSClient_NONMAPREDUCE_-2025447869_1
2017-01-17 19:13:52,780 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/meta/1588230740/WALs/hlog.1484680432166 is closed by DFSClient_NONMAPREDUCE_-2025447869_1
2017-01-17 19:13:52,825 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /hbase/data/hbase/meta/.tmp/.tableinfo.0000000001. blk_7417506133825380805_1005
2017-01-17 19:13:52,839 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addStoredBlock: blockMap updated: 172.24.43.149:50010 is added to blk_7417506133825380805_1005 size 372
2017-01-17 19:13:52,852 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addStoredBlock: blockMap updated: 172.24.43.151:50010 is added to blk_7417506133825380805_1005 size 372
2017-01-17 19:13:52,853 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addStoredBlock: blockMap updated: 172.24.43.150:50010 is added to blk_7417506133825380805_1005 size 372
2017-01-17 19:13:52,856 INFO org.apache.hadoop.hdfs.StateChange: Removing lease on  /hbase/data/hbase/meta/.tmp/.tableinfo.0000000001 from client DFSClient_NONMAPREDUCE_-2025447869_1
2017-01-17 19:13:52,856 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/meta/.tmp/.tableinfo.0000000001 is closed by DFSClient_NONMAPREDUCE_-2025447869_1
2017-01-17 19:13:53,669 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /hbase/WALs/sue-data-1,60020,1484680431984/sue-data-1%2C60020%2C1484680431984.1484680433648. blk_-3943560346518550349_1009
2017-01-17 19:13:53,675 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /hbase/WALs/sue-data-3,60020,1484680431854/sue-data-3%2C60020%2C1484680431854.1484680433646. blk_7474042215333456184_1009
2017-01-17 19:13:53,676 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /hbase/WALs/sue-data-4,60020,1484680431918/sue-data-4%2C60020%2C1484680431918.1484680433650. blk_7488713072756838207_1009
2017-01-17 19:13:53,681 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /hbase/WALs/sue-data-2,60020,1484680431865/sue-data-2%2C60020%2C1484680431865.1484680433650. blk_2116952923143584400_1009
2017-01-17 19:13:53,708 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /hbase/WALs/sue-data-1,60020,1484680431984/sue-data-1%2C60020%2C1484680431984.1484680433648 for DFSClient_hb_rs_sue-data-1,60020,1484680431984_-666160034_43
2017-01-17 19:13:53,723 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /hbase/WALs/sue-data-3,60020,1484680431854/sue-data-3%2C60020%2C1484680431854.1484680433646 for DFSClient_hb_rs_sue-data-3,60020,1484680431854_2084162366_43
2017-01-17 19:13:53,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /hbase/WALs/sue-data-2,60020,1484680431865/sue-data-2%2C60020%2C1484680431865.1484680433650 for DFSClient_hb_rs_sue-data-2,60020,1484680431865_-1883043864_43
2017-01-17 19:13:53,728 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /hbase/WALs/sue-data-4,60020,1484680431918/sue-data-4%2C60020%2C1484680431918.1484680433650 for DFSClient_hb_rs_sue-data-4,60020,1484680431918_873016949_43
2017-01-17 19:13:59,012 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /hbase/WALs/sue-data-3,60020,1484680431854/sue-data-3%2C60020%2C1484680431854.1484680439006.meta. blk_-5670146927121001957_1010
2017-01-17 19:13:59,026 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /hbase/WALs/sue-data-3,60020,1484680431854/sue-data-3%2C60020%2C1484680431854.1484680439006.meta for DFSClient_hb_rs_sue-data-3,60020,1484680431854_2084162366_43
2017-01-17 19:13:59,414 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /hbase/.tmp/data/hbase/namespace/.tmp/.tableinfo.0000000001. blk_5575751580226624776_1011
2017-01-17 19:13:59,535 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addStoredBlock: blockMap updated: 172.24.43.148:50010 is added to blk_5575751580226624776_1011 size 286
2017-01-17 19:13:59,545 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addStoredBlock: blockMap updated: 172.24.43.150:50010 is added to blk_5575751580226624776_1011 size 286
2017-01-17 19:13:59,549 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addStoredBlock: blockMap updated: 172.24.43.151:50010 is added to blk_5575751580226624776_1011 size 286
2017-01-17 19:13:59,552 INFO org.apache.hadoop.hdfs.StateChange: Removing lease on  /hbase/.tmp/data/hbase/namespace/.tmp/.tableinfo.0000000001 from client DFSClient_NONMAPREDUCE_-2025447869_1
2017-01-17 19:13:59,553 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/.tmp/data/hbase/namespace/.tmp/.tableinfo.0000000001 is closed by DFSClient_NONMAPREDUCE_-2025447869_1
2017-01-17 19:13:59,573 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /hbase/.tmp/data/hbase/namespace/86ee9d2d02607f7206e1f04ab98fccb8/.regioninfo. blk_4854178126014073748_1012
2017-01-17 19:13:59,586 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addStoredBlock: blockMap updated: 172.24.43.151:50010 is added to blk_4854178126014073748_1012 size 40
2017-01-17 19:13:59,592 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addStoredBlock: blockMap updated: 172.24.43.149:50010 is added to blk_4854178126014073748_1012 size 40
2017-01-17 19:13:59,593 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addStoredBlock: blockMap updated: 172.24.43.148:50010 is added to blk_4854178126014073748_1012 size 40
2017-01-17 19:13:59,599 INFO org.apache.hadoop.hdfs.StateChange: Removing lease on  /hbase/.tmp/data/hbase/namespace/86ee9d2d02607f7206e1f04ab98fccb8/.regioninfo from client DFSClient_NONMAPREDUCE_-2025447869_1
2017-01-17 19:13:59,599 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hbase/.tmp/data/hbase/namespace/86ee9d2d02607f7206e1f04ab98fccb8/.regioninfo is closed by DFSClient_NONMAPREDUCE_-2025447869_1
2017-01-17 19:15:24,462 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: 'webuser': no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1095)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:58)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:5707)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:2455)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:942)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)
2017-01-17 19:15:24,464 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2017-01-17 19:15:24,471 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: 'webuser': no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1095)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:58)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:5707)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:2455)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:942)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)
2017-01-17 19:15:24,472 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2017-01-17 19:15:24,483 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: 'webuser': no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1095)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:58)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:5707)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:2784)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getListing(NameNode.java:925)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)
2017-01-17 19:15:24,484 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2017-01-17 19:15:38,274 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: 'webuser': no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1095)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:58)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:5707)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:2455)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:942)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)
2017-01-17 19:15:38,275 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2017-01-17 19:15:38,281 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: 'webuser': no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1095)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:58)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:5707)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:2455)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getFileInfo(NameNode.java:942)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)
2017-01-17 19:15:38,282 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2017-01-17 19:15:38,288 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: 'webuser': no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:461)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:444)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:68)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:45)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:79)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1095)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:58)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:5707)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:2784)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.getListing(NameNode.java:925)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)
2017-01-17 19:15:38,289 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user webuser
2017-01-17 19:18:47,536 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.24.43.157
2017-01-17 19:18:47,536 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 80 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 2 Number of syncs: 46 SyncTimes(ms): 35 
2017-01-17 19:18:47,537 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: closing edit log: position=10340, editlog=/app/hadoop/tmp/dfs/name/current/edits
2017-01-17 19:18:47,537 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: close success: truncate to 10340, editlog=/app/hadoop/tmp/dfs/name/current/edits
2017-01-17 19:23:47,580 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.24.43.157
2017-01-17 19:23:47,581 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Cannot roll edit log, edits.new files already exists in all healthy directories:
  /app/hadoop/tmp/dfs/name/current/edits.new
2017-01-17 19:28:47,588 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.24.43.157
2017-01-17 19:28:47,589 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Cannot roll edit log, edits.new files already exists in all healthy directories:
  /app/hadoop/tmp/dfs/name/current/edits.new
2017-01-17 19:31:34,710 INFO org.apache.hadoop.hdfs.StateChange: *BLOCK* processReport: from 172.24.43.148:50010, blocks: 5, processing time: 0 msecs
2017-01-17 19:33:47,598 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.24.43.157
2017-01-17 19:33:47,598 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Cannot roll edit log, edits.new files already exists in all healthy directories:
  /app/hadoop/tmp/dfs/name/current/edits.new
2017-01-17 19:38:47,606 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.24.43.157
2017-01-17 19:38:47,607 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Cannot roll edit log, edits.new files already exists in all healthy directories:
  /app/hadoop/tmp/dfs/name/current/edits.new
2017-01-17 19:43:47,613 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.24.43.157
2017-01-17 19:43:47,613 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Cannot roll edit log, edits.new files already exists in all healthy directories:
  /app/hadoop/tmp/dfs/name/current/edits.new
2017-01-17 19:47:04,857 INFO org.apache.hadoop.hdfs.StateChange: *BLOCK* processReport: from 172.24.43.149:50010, blocks: 6, processing time: 0 msecs
2017-01-17 19:48:47,630 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.24.43.157
2017-01-17 19:48:47,630 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Cannot roll edit log, edits.new files already exists in all healthy directories:
  /app/hadoop/tmp/dfs/name/current/edits.new
2017-01-17 19:51:34,906 INFO org.apache.hadoop.hdfs.StateChange: *BLOCK* processReport: from 172.24.43.150:50010, blocks: 4, processing time: 0 msecs
2017-01-17 19:53:47,647 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 172.24.43.157
2017-01-17 19:53:47,647 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Cannot roll edit log, edits.new files already exists in all healthy directories:
  /app/hadoop/tmp/dfs/name/current/edits.new
2017-01-17 19:54:58,962 INFO org.apache.hadoop.hdfs.StateChange: *BLOCK* processReport: from 172.24.43.151:50010, blocks: 6, processing time: 0 msecs
